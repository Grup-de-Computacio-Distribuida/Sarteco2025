@article{aroraModelingQueryingData2013,
  title = {Modeling and {{Querying Data}} in {{MongoDB}}},
  author = {Arora, Rupali and Aggarwal, Rinkle Rani},
  year = {2013},
  volume = {4},
  number = {7},
  abstract = {With the uninterrupted growth of data volumes, the storage of information, support and maintenance have become the biggest challenge. Relational database products fall behind to scaling the applications according to the incoming traffic. Due to huge data storage and scaling demands, growing number of developers and users have begun turning to NoSQL databases. This paper describes data modeling and query execution in MongoDB Document database. This paper shows how data is retrieved from MongoDB Document database without using JOIN.},
  langid = {english},
  file = {/home/jordigv/Zotero/storage/TQ3TQE65/Arora and Aggarwal - 2013 - Modeling and Querying Data in MongoDB.pdf}
}

@inproceedings{bagaskaraPerformanceAnalysisMessage2020,
  title = {Performance {{Analysis}} of {{Message Broker}} for {{Communication}} in {{Fog Computing}}},
  booktitle = {2020 12th {{International Conference}} on {{Information Technology}} and {{Electrical Engineering}} ({{ICITEE}})},
  author = {Bagaskara, Aditya Eka and Setyorini, Setyorini and Wardana, Aulia Arif},
  year = {2020},
  month = oct,
  pages = {98--103},
  doi = {10.1109/ICITEE49829.2020.9271733},
  urldate = {2024-05-28},
  abstract = {In this research, performance testing is performed between the two most popular message brokers, which commonly used in the enterprise, namely RabbitMQ and Apache Kafka in the fog computing environment. REST API is a method that implements the HTTP protocol and commonly used in the Internet of Things as a communication media between devices. Hence the performance will degrade when the amount of request is abundant and less reliable due to its synchronous communication. By using a message broker as the medium of communication between devices in fog computing, each connected device will not rely on each other and will make the message delivery more guaranteed. By reason, this research will implement a message broker for communication between devices in fog computing. Today there are many message brokers developed by various companies or communities. Choosing an unsuitable message broker can cause performance degradation, which results in a chaotic IoT system. The test results show that Apache Kafka has a higher throughput than RabbitMQ when the message size is calculable. However, when the message size is myriad, RabbitMQ is much better because the bottleneck of disk I/O usage occurred in Kafka. Nevertheless, in latency testing, RabbitMQ is always better even though the difference is not too far. This testing can also be concluded that the use of message broker in fog computing that extends the cloud computing architecture proven effective in implementing the IoT system.},
  keywords = {Cloud computing,Cloud Computing,Edge computing,Fog Computing,Kafka,Message Broker,Performance evaluation,RabbitMQ,Random access memory,Testing,Throughput,Tools},
  file = {/home/jordigv/Zotero/storage/PQKHDX6P/Bagaskara et al. - 2020 - Performance Analysis of Message Broker for Communi.pdf}
}

@article{baziotisDiasDynamicRewriting2024,
  title = {Dias: {{Dynamic Rewriting}} of {{Pandas Code}}},
  shorttitle = {Dias},
  author = {Baziotis, Stefanos and Kang, Daniel and Mendis, Charith},
  year = {2024},
  month = mar,
  journal = {Proceedings of the ACM on Management of Data},
  volume = {2},
  number = {1},
  pages = {58:1--58:27},
  doi = {10.1145/3639313},
  urldate = {2024-05-28},
  abstract = {In recent years, dataframe libraries, such as pandas have exploded in popularity. Due to their flexibility, they are increasingly used in ad-hoc exploratory data analysis (EDA) workloads. These workloads are diverse, including custom functions which can span libraries or be written in pure Python. The majority of systems available to accelerate EDA workloads focus on bulk-parallel workloads, which contain vastly different computational patterns, typically within a single library. As a result, they can introduce excessive overheads for ad-hoc EDA workloads due to their expensive optimization techniques. Instead, we identify source-to-source, external program rewriting as a lightweight technique which can optimize across representations, and offer substantial speedups while also avoiding slowdowns. We implemented Dias, which rewrites notebook cells to be more efficient for ad-hoc EDA workloads. We develop techniques for efficient rewrites in Dias, including checking the preconditions under which rewrites are correct, dynamically, at fine-grained program points. We show that Dias can rewrite individual cells to be 57{\texttimes} faster compared to pandas and 1909{\texttimes} faster compared to optimized systems such as modin. Furthermore, Dias can accelerate whole notebooks by up to 3.6{\texttimes} compared to pandas and 27.1{\texttimes} compared to modin.},
  keywords = {cross-representation,dynamic,pandas,rewriting},
  file = {/home/jordigv/Zotero/storage/5492R2IR/Baziotis et al. - 2024 - Dias Dynamic Rewriting of Pandas Code.pdf}
}

@article{chauhanUsingAdvantagesNOSQL2017,
  title = {Using the {{Advantages}} of {{NOSQL}}: {{A Case Study}} on {{MongoDB}}},
  shorttitle = {Using the {{Advantages}} of {{NOSQL}}},
  author = {Chauhan, Divya and Bansal, Kartik},
  year = {2017},
  month = feb,
  journal = {International Journal on Recent and Innovation Trends in Computing and Communication},
  volume = {5},
  pages = {90--93},
  abstract = {With such a big volume of data growing tremendously every day, the storage of information, support and maintenance have become difficult. A further level of difficulty is added by the variety of data being captured. The data stored and updated on daily bases is in the form of logs, audio, video, sensor data and so on, which is not easy to be stored and queried using relational database. The paper gives the overview of NOSQL databases which provide more scalability and efficiency in storage and access of the data. A case study on MongoDB is done as to show the representational format and querying process of NOSQL database. The concepts of MongoDB are compared to the relational databases.},
  file = {/home/jordigv/Zotero/storage/PJXCF8MG/Chauhan and Bansal - 2017 - Using the Advantages of NOSQL A Case Study on Mon.pdf}
}

@article{florensaAcetylsalicylicAcidEffect2023,
  title = {Acetylsalicylic {{Acid Effect}} in {{Colorectal Cancer Taking}} into {{Account}} the {{Role}} of {{Tobacco}}, {{Alcohol}} and {{Excess Weight}}},
  author = {Florensa, Didac and Mateo, Jordi and Solsona, Francesc and Galv{\'a}n, Leonardo and Mesas, Miquel and Pi{\~n}ol, Ramon and {Espinosa-Leal}, Leonardo and Godoy, Pere},
  year = {2023},
  journal = {International journal of environmental research and public health},
  volume = {20},
  number = {5},
  pages = {4104-},
  publisher = {MDPI AG},
  address = {Switzerland},
  issn = {1660-4601},
  doi = {10.3390/ijerph20054104},
  abstract = {Excess weight, smoking and risky drinking are preventable risk factors for colorectal cancer (CRC). However, several studies have reported a protective association between aspirin and the risk of CRC. This article looks deeper into the relationships between risk factors and aspirin use with the risk of developing CRC. We performed a retrospective cohort study of CRC risk factors and aspirin use in persons aged {$>$}50 years in Lleida province. The participants were inhabitants with some medication prescribed between 2007 and 2016 that were linked to the Population-Based Cancer Registry to detect CRC diagnosed between 2012 and 2016. Risk factors and aspirin use were studied using the adjusted HR (aHR) with 95\% confidence intervals (CI) using a Cox proportional hazard model. We included 154,715 inhabitants of Lleida (Spain) aged {$>$}50 years. Of patients with CRC, 62\% were male (HR = 1.8; 95\% CI: 1.6-2.2), 39.5\% were overweight (HR = 2.8; 95\% CI: 2.3-3.4) and 47.3\% were obese (HR = 3.0; 95\% CI: 2.6-3.6). Cox regression showed an association between aspirin and CRC (aHR = 0.7; 95\% CI: 0.6-0.8), confirming a protective effect against CRC and an association between the risk of CRC and excess weight (aHR = 1.4; 95\% CI: 1.2-1.7), smoking (aHR = 1.4; 95\% CI: 1.3-1.7) and risky drinking (aHR = 1.6; 95\% CI: 1.2-2.0). Our results show that aspirin use decreased the risk of CRC and corroborate the relationship between overweight, smoking and risky drinking and the risk of CRC.},
  langid = {english},
  keywords = {Aspirin,Body mass index,Body weight,Cancer,Cohort analysis,Colorectal Neoplasms,Confidence intervals,Drinking behavior,Drugstores,Ethanol,Female,Health aspects,Human beings,Male,Models Statistical,Mortality,Obesity,Oncology Experimental,Research,Retrospective Studies,Risk factors,Salicylates,Smoking,Statistics,Tobacco,Weight gain},
  file = {/home/jordigv/Zotero/storage/YBN96XNW/Florensa et al. - 2023 - Acetylsalicylic Acid Effect in Colorectal Cancer T.pdf}
}

@article{florensacazorlaLowdoseAcetylsalicylicAcid2023,
  title = {Low-Dose Acetylsalicylic Acid for Cancer Prevention Considering Risk Factors: A Retrospective Cohort Study},
  shorttitle = {Low-Dose Acetylsalicylic Acid for Cancer Prevention Considering Risk Factors},
  author = {Florensa Cazorla, D{\'i}dac and Mateo Forn{\'e}s, Jordi and Solsona Teh{\`a}s, Francesc and Galv{\'a}n, Leonardo and Mesas, Miquel and Pi{\~n}ol, Ramon and {Espinosa-Leal}, Leonardo and {Godoy i Garc{\'i}a}, Pere},
  year = {2023},
  publisher = {Elsevier},
  issn = {1047-2797},
  urldate = {2024-05-28},
  abstract = {Purpose Aspirin (acetylsalicylic acid) has been reported to protect against certain cancers. However, patient-related risk factors may moderate protective effects, including excess weight, smoking, risky alcohol use, and diabetes. We explore the cancer-risk relationship between aspirin intake and those four factors. Methods Retrospective cohort study of cancers, aspirin intake, and four risk factors in persons aged {$\geq$}50 years. Participants received medication during 2007--2016, and cancers were diagnosed in 2012--2016. Adjusted hazard ratios (aHR) for 95\% confidence intervals (95\%CI) were calculated for aspirin intake and risk factors using Cox proportional hazard modeling. Results Of 118,548 participants, 15,793 consumed aspirin, and 4003 had cancer. Results indicated a significant protective effect of aspirin against colorectal (aHR: 0.7; 95\%CI: 0.6--0.8), pancreatic (aHR: 0.5; 95\%CI: 0.2--0.9), prostate (aHR: 0.6; 95\%CI: 0.5--0.7) cancers and lymphomas (aHR: 0.5; 95\%CI: 0.2--0.9), and also, although not significantly, against esophageal (aHR: 0.5; 95\%CI: 0.2--1.8), stomach (aHR: 0.7; 95\%CI: 0.4--1.3), liver (aHR: 0.7; 95\%CI: 0.3--1.5), breast (aHR: 0.8; 95\%CI: 0.6--1.0), and lung and bronchial (aHR: 0.9; 95\%CI: 0.7--1.2) cancers. Aspirin intake was not significantly protective against leukemia (aHR: 1.0; 95\%CI: 0.7--1.4) or bladder cancer (aHR: 1.0; 95\%CI: 0.8--1.3). Conclusions Our results suggest that aspirin intake is associated with a reduced incidence of colorectal, pancreatic, and prostate cancers and lymphomas.},
  langid = {english},
  file = {/home/jordigv/Zotero/storage/TRPKINC2/Florensa Cazorla et al. - 2023 - Low-dose acetylsalicylic acid for cancer preventio.pdf}
}

@phdthesis{frailealonsoDesenvolupamentEinaGenerica,
  type = {Bachelor's {{Thesis}}},
  title = {Desenvolupament d'una Eina Gen{\`e}rica per a l'aplicaci{\'o} de T{\`e}cniques de Computaci{\'o} Avan{\c c}ada En El Registre de C{\`a}ncer Poblacional de {{Lleida}}},
  author = {Fraile Alonso, Pablo},
  abstract = {In an era driven by data, the healthcare industry has amassed an unprecedented wealth of patient information, offering tremendous potential for revolutionizing medicine. However, the underutilization of this vast repository hinders progress in disease prevention and public health initiatives. This article focuses on the critical need for a generic tool that can effectively analyze, filter, and visualize the positive relationships between medication exposure and cancer incidence or treatment. Leveraging advanced algorithms and data processing techniques, such a tool can unlock invaluable insights from extensive datasets, empowering researchers and medical professionals to identify meaningful patterns and correlations. By understanding the intricate link between medication exposure and cancer risk, healthcare providers can tailor treatment plans, assess risks, and develop preventive strategies. This work contributes a comprehensive tool, built upon a clean-architecture project, that can analyze large-scale datasets, offering the flexibility to adapt it to different healthcare services. Additionally, a database comprising the study results of 1,500 medicines and 20 different cancers in the population of Lleida is provided. The experimentation and analysis performed unveil significant relationships between specific cancers and medicines, providing valuable insights for healthcare data analysis. Keywords: healthcare data analysis, medication exposure, cancer risk, clean-architecture, data processing, pattern recognition.},
  school = {Universitat de Lleida}
}

@article{godoygarciaExploringCancerIncidence2023,
  title = {{Exploring Cancer Incidence, Risk Factors, and Mortality in the Lleida Region: Interactive, Open-source R Shiny Application for Cancer Data Analysis}},
  shorttitle = {{Exploring Cancer Incidence, Risk Factors, and Mortality in the Lleida Region}},
  author = {Godoy Garcia, Pere and Florensa Cazorla, Didac and Solsona Tehas, Francesc Xavier and L{\'o}pez Sorribes, Sergi and Mateo Forn{\'e}s, Jordi},
  year = {2023},
  month = apr,
  publisher = {JMIR PUBLICATIONS, INC},
  issn = {2369-1999},
  doi = {10.2196/44695},
  urldate = {2024-05-28},
  langid = {catalan},
  file = {/home/jordigv/Zotero/storage/GXIVMS7J/Godoy Garcia et al. - 2023 - Exploring Cancer Incidence, Risk Factors, and Mort.pdf;/home/jordigv/Zotero/storage/8UYRY8VR/44695.html}
}

@article{jindalMagpiePythonSpeed2021,
  title = {Magpie: {{Python}} at {{Speed}} and {{Scale}} Using {{Cloud Backends}}},
  author = {Jindal, Alekh and Emani, K Venkatesh and Daum, Maureen and Poppe, Olga and Haynes, Brandon and Pavlenko, Anna and Gupta, Ayushi and Ramachandra, Karthik and Curino, Carlo and Mueller, Andreas and Wu, Wentao and Patel, Hiren},
  year = {2021},
  abstract = {Python has become overwhelmingly popular for ad-hoc data analysis, and Pandas dataframes have quickly become the de facto standard API for data science. However, performance and scaling to large datasets remain significant challenges. This is in stark contrast with the world of databases, where decades of investments have led to both sub-millisecond latencies for small queries and many orders of magnitude better scalability for large analytical queries. Furthermore, databases offer enterprise-grade features (e.g., transactions, fine-grained access control, tamper-proof logging, encryption) as well as a mature ecosystem of tools in modern clouds.},
  langid = {english},
  file = {/home/jordigv/Zotero/storage/93UHI3RG/Jindal et al. - 2021 - Magpie Python at Speed and Scale using Cloud Back.pdf}
}

@misc{johnSurveyDistributedMessage2017a,
  title = {A {{Survey}} of {{Distributed Message Broker Queues}}},
  author = {John, Vineet and Liu, Xia},
  year = {2017},
  month = apr,
  number = {arXiv:1704.00411},
  eprint = {1704.00411},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1704.00411},
  urldate = {2024-05-28},
  abstract = {This paper surveys the message brokers that are in vogue today for distributed communication. Their primary goal is to facilitate the construction of decentralized topologies without single points of failure, enabling fault tolerance and high availability. These characteristics make them optimal for usage within distributed architectures. However, there are multiple protocols built to achieve this, and it would be beneficial to have a empirical comparison between their features and performance to determine their real-world applicability. This paper focuses on two popular protocols (Kafka and AMQP) and explores the divergence in their features as well as their performance under varied testing workloads.},
  archiveprefix = {arXiv},
  keywords = {68M14,C.1.4,Computer Science - Distributed Parallel and Cluster Computing},
  file = {/home/jordigv/Zotero/storage/F7HCAWUY/John and Liu - 2017 - A Survey of Distributed Message Broker Queues.pdf;/home/jordigv/Zotero/storage/7UL3C6UL/1704.html}
}

@inproceedings{kanadeStudyNormalizationEmbedding2014,
  title = {A Study of Normalization and Embedding in {{MongoDB}}},
  booktitle = {2014 {{IEEE International Advance Computing Conference}} ({{IACC}})},
  author = {Kanade, Anuradha and Gopal, Arpita and Kanade, Shantanu},
  year = {2014},
  month = feb,
  pages = {416--421},
  doi = {10.1109/IAdCC.2014.6779360},
  urldate = {2024-05-28},
  abstract = {With the advancement in the database technology NoSQL databases are becoming more and more popular now a days. The cloud-based NoSQL database MongoDB is one of them. As one can know the data modeling strategies for relational and non-relational databases differ drastically. Modeling of data in MongoDB database depends on the data and characteristics of MongoDB. Due to variation in data models MongoDB based application performance gets affected. In the present paper we have applied two different modeling styles as embedding of documents and normalization on collections. With the embedding feature we may face situation where documents grow in size after creation which may degrade the performance of database. The maximum document size allowed in MongoDB is limited. With references we get maximum flexibility than embedding but client-side applications must issue follow-up queries to resolve the references. The joins in this case cannot be effectively used. Hence there is need for defining the strategy of extent of normalization and embedding to get better performance in the mixed situation. The paper discussed here shows the variation in the performance along with the change in the modeling style with reference to normalization and embedding and it gives the base to find the extent of normalization and embedding for reducing query execution time.},
  keywords = {Computational modeling,Conferences,Data models,Denormalization,Embedding,MongoDB,Noise measurement,Normalization,NoSQL,Query processing,Query Processing Time,RDBMS,Relational databases,Zettabytes},
  file = {/home/jordigv/Zotero/storage/SH3XZN2B/Kanade et al. - 2014 - A study of normalization and embedding in MongoDB.pdf}
}

@article{masAutoscalingPodsOnPremise2022,
  title = {Autoscaling {{Pods}} on an {{On-Premise Kubernetes Infrastructure QoS-Aware}}},
  author = {Mas, Lluis and Pi{\~n}ol Pueyo, Pere and Mateo Forn{\'e}s, Jordi and Vilaplana Mayoral, Jordi and Solsona Teh{\`a}s, Francesc},
  year = {2022},
  publisher = {{Institute of Electrical and Electronics Engineers}},
  issn = {2169-3536},
  urldate = {2024-05-28},
  abstract = {Cloud systems and microservices are becoming powerful tools for businesses. The evidence of the advantages of offering infrastructure, hardware or software as a service (IaaS, PaaS, SaaS) is overwhelming. Microservices and decoupled applications are increasingly popular. These architectures, based on containers, have facilitated the efficient development of complex SaaS applications. A big challenge is to manage and design microservices with a massive range of different facilities, from processing and data storage to computing predictive and prescriptive analytics. Computing providers are mainly based on data centers formed of massive and heterogeneous virtualized systems, which are continuously growing and diversifying over time. Moreover, these systems require integrating into current systems while meeting the Quality of Service (QoS) constraints. The primary purpose of this work is to present an on-premise architecture based on Kubernetes and Docker containers aimed at improving QoS regarding resource usage and service level objectives (SLOs). The main contribution of this proposal is its dynamic autoscaling capabilities to adjust system resources to the current workload while improving QoS.},
  langid = {english},
  file = {/home/jordigv/Zotero/storage/ZLYVHFBE/Mas et al. - 2022 - Autoscaling Pods on an On-Premise Kubernetes Infra.pdf}
}

@misc{petersohnScalableDataframeSystems2020,
  title = {Towards {{Scalable Dataframe Systems}}},
  author = {Petersohn, Devin and Macke, Stephen and Xin, Doris and Ma, William and Lee, Doris and Mo, Xiangxi and Gonzalez, Joseph E. and Hellerstein, Joseph M. and Joseph, Anthony D. and Parameswaran, Aditya},
  year = {2020},
  month = jun,
  number = {arXiv:2001.00888},
  eprint = {2001.00888},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2024-05-28},
  abstract = {Dataframes are a popular abstraction to represent, prepare, and analyze data. Despite the remarkable success of dataframe libraries in R and Python, dataframes face performance issues even on moderately large datasets. Moreover, there is significant ambiguity regarding dataframe semantics. In this paper we lay out a vision and roadmap for scalable dataframe systems. To demonstrate the potential in this area, we report on our experience building MODIN, a scaled-up implementation of the most widely-used and complex dataframe API today, Python's pandas. With pandas as a reference, we propose a simple data model and algebra for dataframes to ground discussion in the field. Given this foundation, we lay out an agenda of open research opportunities where the distinct features of dataframes will require extending the state of the art in many dimensions of data management. We discuss the implications of signature dataframe features including flexible schemas, ordering, row/column equivalence, and data/metadata fluidity, as well as the piecemeal, trial-and-error-based approach to interacting with dataframes.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Databases},
  file = {/home/jordigv/Zotero/storage/4ANRKMKZ/Petersohn et al. - 2020 - Towards Scalable Dataframe Systems.pdf}
}

@inproceedings{reddyPerformanceStudyKubernetes2022,
  title = {Performance {{Study}} of {{Kubernetes Cluster Deployed}} on {{Openstack}},{{VMs}} and {{BareMetal}}},
  booktitle = {2022 {{IEEE International Conference}} on {{Electronics}}, {{Computing}} and {{Communication Technologies}} ({{CONECCT}})},
  author = {Reddy, Yeddula Sai Dhanush and Reddy, Padumati Saikiran and Ganesan, Nithya and Thangaraju, B.},
  year = {2022},
  month = jul,
  pages = {1--5},
  issn = {2766-2101},
  doi = {10.1109/CONECCT55679.2022.9865718},
  urldate = {2024-05-28},
  abstract = {Kubernetes is an OpenSource Orchestration tool used for deploying and managing containerized applications at scale. Kubernetes easily manages the cluster with a master and worker nodes in which the Pods are been hosted. Nowadays many Cloud Infrastructure Providers like AWS, GoogleCloud, and Microsoft Azure understand the importance of Kubernetes and have added these services to their products. Openstack is a novel and highly manageable OpenSource cloud IaaS platform where the components manage huge pools of compute, storage, and networking resources. In this experimental work we studied and compared the local deployment of Kubernetes Cluster using minikube with the VM deployment and OpenStack deployment. A demo application with microservices Architecture has been taken for this study in which we compare the CPU and Memory Usage on the deployment of the cluster in OpenStack, VMs and BareMetal. The preliminary results show that the bare-metal deployment outperforms the other deployments in both Computing and Memory intensive applications.},
  keywords = {Communications technology,Computer architecture,Containers,Docker,Kubernetes,Microservice architectures,MicroServices,OpenStack,Software Defined Networking (SDN)},
  file = {/home/jordigv/Zotero/storage/SHLXWP9S/Reddy et al. - 2022 - Performance Study of Kubernetes Cluster Deployed o.pdf}
}

@article{reySeamlessIntegrationParquet2023,
  title = {Seamless {{Integration}} of {{Parquet Files}} into {{Data Processing}}},
  author = {Rey, Alice and Freitag, Michael and Neumann, Thomas},
  year = {2023},
  publisher = {Gesellschaft f{\"u}r Informatik e.V.},
  doi = {10.18420/BTW2023-12},
  urldate = {2024-05-28},
  abstract = {Relational database systems are still the most powerful tool for data analysis. However, the steps necessary to bring existing data into the database make them unattractive for data exploration, especially when the data is stored in data lakes where users often use Parquet files, a binary column-oriented file format.},
  isbn = {9783885797258},
  langid = {english},
  file = {/home/jordigv/Zotero/storage/68P8NCQK/Rey et al. - 2023 - Seamless Integration of Parquet Files into Data Pr.pdf}
}

@inproceedings{telenykComparisonKubernetesKubernetesCompatible2021,
  title = {A {{Comparison}} of {{Kubernetes}} and {{Kubernetes-Compatible Platforms}}},
  booktitle = {2021 11th {{IEEE International Conference}} on {{Intelligent Data Acquisition}} and {{Advanced Computing Systems}}: {{Technology}} and {{Applications}} ({{IDAACS}})},
  author = {Telenyk, Sergii and Sopov, Oleksii and Zharikov, Eduard and Nowakowski, Grzegorz},
  year = {2021},
  month = sep,
  pages = {313--317},
  publisher = {IEEE},
  address = {Cracow, Poland},
  doi = {10.1109/IDAACS53288.2021.9660392},
  urldate = {2024-05-28},
  abstract = {Nowadays, Kubernetes is an advanced container orchestration tool due to its high reliability, scalability and fault tolerance. However, Kubernetes requires a significant number of resources for its work. Therefore, to ensure the operation of Kubernetes in conditions of limited resources, lightweight analogues such as MicroKubernetes and K3S were created. These platforms provide easier deployment and support. In this paper, the authors analyze performance metrics for orchestration actions such as adding/removing nodes and starting/stopping deployments in terms of resource utilization, cluster startup speed, and consumed time for lightweight platforms and original Kubernetes. The results show that the original Kubernetes outperforms MicroKubernetes and K3S in many tests, but K3S demonstrates better disk utilization. On the other hand, MicroKubernetes demonstrates worst results in the performed tests.},
  copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
  isbn = {978-1-66542-605-3},
  langid = {english},
  file = {/home/jordigv/Zotero/storage/WHWJKVX8/Telenyk et al. - 2021 - A Comparison of Kubernetes and Kubernetes-Compatib.pdf}
}

@article{truyenComprehensiveFeatureComparison2019,
  title = {A {{Comprehensive Feature Comparison Study}} of {{Open-Source Container Orchestration Frameworks}}},
  author = {Truyen, Eddy and Van Landuyt, Dimitri and Preuveneers, Davy and Lagaisse, Bert and Joosen, Wouter},
  year = {2019},
  month = jan,
  journal = {Applied Sciences},
  volume = {9},
  number = {5},
  pages = {931},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2076-3417},
  doi = {10.3390/app9050931},
  urldate = {2024-05-28},
  abstract = {(1) Background: Container orchestration frameworks provide support for management of complex distributed applications. Different frameworks have emerged only recently, and they have been in constant evolution as new features are being introduced. This reality makes it difficult for practitioners and researchers to maintain a clear view of the technology space. (2) Methods: we present a descriptive feature comparison study of the three most prominent orchestration frameworks: Docker Swarm, Kubernetes, and Mesos, which can be combined with Marathon, Aurora or DC/OS. This study aims at (i) identifying the common and unique features of all frameworks, (ii) comparing these frameworks qualitatively and quantitatively with respect to genericity in terms of supported features, and (iii) investigating the maturity and stability of the frameworks as well as the pioneering nature of each framework by studying the historical evolution of the frameworks on GitHub. (3) Results: (i) we have identified 124 common features and 54 unique features that we divided into a taxonomy of 9 functional aspects and 27 functional sub-aspects. (ii) Kubernetes supports the highest number of accumulated common and unique features for all 9 functional aspects; however, no evidence has been found for significant differences in genericity with Docker Swarm and DC/OS. (iii) Very little feature deprecations have been found and 15 out of 27 sub-aspects have been identified as mature and stable. These are pioneered in descending order by Kubernetes, Mesos, and Marathon. (4) Conclusion: there is a broad and mature foundation that underpins all container orchestration frameworks. Likely areas for further evolution and innovation include system support for improved cluster security and container security, performance isolation of GPU, disk and network resources, and network plugin architectures.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {commonality and variability analysis,container orchestration frameworks,feature deprecation risk,genericity,maturity of features,middleware for cloud-native applications},
  file = {/home/jordigv/Zotero/storage/W3E6BTWA/Truyen et al. - 2019 - A Comprehensive Feature Comparison Study of Open-S.pdf}
}

@article{yerleLiveMigrationContainers2022,
  title = {{Live Migration of Containers in Cloud Computing and Multicloud}},
  author = {Yerle, Carlos Mart{\'i}n},
  year = {2022},
  month = oct,
  publisher = {Universitat Polit{\`e}cnica de Val{\`e}ncia},
  urldate = {2024-05-28},
  abstract = {[EN] In cloud computing and recent distributed computing paradigms (e.g., serverless),  containers are key to provide the necessary agility in highly flexible load balancing,  machine fault management, scaling and resource management of a server.  However, how to move (scale, redeploy) these containers, can still be problematic,  and therefore we will investigate what technologies exist for the live migration  process of containers in cloud computing and more precisely in multicloud.  This process will be analyzed both for the trivial case of stateless containers,  where the only additional information is stored on the client (your browser), such as  cookies or local storage, and in the case of stateful container migration, where we  have additional information stored on the server that will need to be treated in a  special way when migrating (e.g., volumes, replicated persistent storage and the  like).  Once we discover how this process works in the traditional cloud, we will  investigate how these techniques apply to the multicloud. We will look at what  challenges we face in this process and analyses how the OpenNebula platform works  in particular. Open-source platform that offers live migration services that work in the  multicloud, but no solution is perfect. This assessment will also seek to address some  of the shortcomings of the technologies.},
  copyright = {Reconocimiento (by)},
  langid = {Ingl{\'e}s},
  annotation = {Accepted: 2022-10-18T07:03:12Z},
  file = {/home/jordigv/Zotero/storage/8RNYYYVL/Yerle - 2022 - Live Migration of Containers in Cloud Computing an.pdf}
}

@inproceedings{zhuComparativeStudySpark2020,
  title = {A {{Comparative Study}} of {{Spark}} on the Bare Metal and {{Kubernetes}}},
  booktitle = {2020 6th {{International Conference}} on {{Big Data}} and {{Information Analytics}} ({{BigDIA}})},
  author = {Zhu, Changpeng and Han, Bo and Zhao, Yinliang},
  year = {2020},
  month = dec,
  pages = {117--124},
  doi = {10.1109/BigDIA51454.2020.00027},
  urldate = {2024-05-28},
  abstract = {Kubernetes makes it easier to automate deployment and scale containerized applications to achieve near-native performance in cloud environment. However, there still lacks a systematic comparison study on how Spark applications perform between on the bare metal and on Kubernetes. In this paper, we focus on the performance evaluation of these applications running on the two environments by a series of experiments. Based on these experiments, we locate what stages cause their performance gap and reveal out root causes to the gap by analysing work-flows of these Spark applications and their resource costs. Through extensive measurements, we find out that Spark on the bare metal almost always contribute to better performance when compared with Spark on Kubernetes. More CPU usage of executors and better data locality on the bare metal are the root causes to the gap. By contrast, Spark on Kubernetes also has some its advantages over Spark on the bare metal in terms of disk W-IOPs. The research work in this paper can help practitioners and researchers to make more informed decisions on tuning their cloud environment and configuring the big data applications, so as to achieve better performance and higher resources utilization.},
  keywords = {Big Data applications,Encapsulation,Kubernetes,Metals,Performance evaluation,Performance Evaluation,Root Causes,Spark,Sparks,Systematics,Tuning},
  file = {/home/jordigv/Zotero/storage/LBKVYRWN/Zhu et al. - 2020 - A Comparative Study of Spark on the bare metal and.pdf;/home/jordigv/Zotero/storage/BR2A689B/9384578.html}
}
