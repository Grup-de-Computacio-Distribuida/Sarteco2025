---
title: "Optimizing Workflows in Distributed Systems"
subtitle: "A Case Study for the Lleida Population Cancer Registry" 
author:
  - name: Didac Florensa
    affiliation: University of Lleida
  - name: Jordi Vilaplana
    affiliation: University of Lleida
  - name: Jordi Mateo
    affiliation: University of Lleida
  - name: Jordi Garcia
    affiliation: University of Lleida
  - name: Pablo Fraile
    affiliation: University of Lleida
logo: "logo.png"
footer: "Jornadas Sarteco 2025"
bibliography: references.bib
format: 
  revealjs:
    #theme: slides.scss
    transition: fade
    slide-number: true
    incremental: true 
    chalkboard: true
    toc: true
    toc-depth: 1
editor: visual
execute:
  freeze: auto
  echo: true
mermaid:
      theme: neutral
---

## Introduction {.smaller}

::: {.callout-tip title="Context"}
This work was part of an **Industrial PhD**, @florensamachine, collaboration between the Population Cancer Registry, Arnau de Vilanova Hospital, and the University of Lleida.
:::

. . .

::: {.callout-warning title="Purpose"}
Develop an **optimized platform** that enables *high-quality data* for identifying associations between medications and cancer types within the Lleida population registry.
:::

. . .

::: {.callout-note title="Publications Related"}

1. @florensa2023low -> Low-dose acetylsalicylic acid for cancer prevention
2. @florensa2023diabetes -> Metformin and association with pancreas cancer
:::

. . .

::: {.callout-important title="Team"}
- **Dídac Florensa**: PhD student, responsible for data management, analysis, and requirements gathering.
- **Pablo Fraile** and **Jordi Garcia**: Master's and Bachelor's students, respectively, responsible for implementing and developing the platform.
- **Jordi Mateo** and **Jordi Vilaplana**: Professors at the University of Lleida, leading the project.
:::

## Problem Statement {.smaller}

::: columns
::: {.column width="30%" .fragment}

::: {.callout-tip title="Goal"}
**Analyze associations**: *Medication* and *cancer* type effects on patient survival (protective or harmful).
:::

:::
::: {.column width="35%" .fragment}

::: {.callout-warning title="Challenge"}
Analyzing **79,931** combinations of medications and cancer types from *2007-2019*.
:::

:::
::: {.column width="35%" .fragment}

::: {.callout-important title="Inital Approach"}
A *single machine* would require **61 days** to complete this analysis, with each combination consuming **66 seconds**.
:::

:::
:::

. . .

![](figures/original.png){width=80%}


## Profiling {.smaller}

::: columns

::: {.column width="35%" .fragment}
::: {.callout-tip title="Goal"}
- Identify **bottlenecks**
- Identify **inefficiencies**
- Propose **optimizations**
:::
:::
  
::: {.column width="40%" .fragment}
::: {.callout-important title="Findings"}
- Data not retrieved in a **single** query  
- **Join-like**  applied on a *non-relational DB*  
- Queries misaligned with schema structure  
:::
:::
  
::: {.column width="25%" .fragment}
::: {.callout-note title="Proposals"}
- Schema redesign based on **query** access patterns.
:::

:::
:::

. . .

::: columns

::: {.column width="33%"}
#### Yearly Schema 
```{.json code-line-numbers="false"}
{
  "expositions": {
    "2017": {
      "J01FA09": 100,
      "J01FA10": 200
    },
    "2018": {
      "J01FA09": 150,
      "J01FA10": 250
    },..
  }
}
```
:::

::: {.column width="33%"}
#### ATC Code Schema

```{.json code-line-numbers="false"}
{
  "expositions": {
    "J01FA09": {
      "2017": 100,
      "2018": 150
    },
    "J01FA10": {
      "2017": 200,
      "2018": 250
    },...
  }
}
```
:::

::: {.column width="33%"}
#### Flattened Schema

```{.json code-line-numbers="false"}
{
  "expositions": [
    { "atc": "J01FA09", 
      "year": 2017, 
      "dose": 100 },
    { "atc": "J01FA09", 
      "year": 2018, 
      "dose": 150 },
    ...
  ]
}
```
:::

:::

## Data schema impact {.smaller}

::: columns
::: {.column width="50%" .fragment}

![](figures/db_sizes.png)

:::
::: {.column width="50%" .fragment}

![](figures/query_time.png)

:::
:::

. . .

::: {.callout-tip title="Observation"}
Proposed solutions **reduce query time** (at the cost of disk space for indexes). However, *deserialization time* **increases** across all proposals.
:::

. . .

::: {.callout-important title="Next Steps"}
How can we simultaneously minimize deserialization time and reduce query execution?
:::

## Deserialization {.smaller}

::: columns
::: {.column width="40%" .fragment}

::: {.callout-important title="Findings"}
- PyMongo returns Python dictionaries → slow for large result sets  
- PyMongoArrow improves typing, but still memory-heavy  
- Optimal performance requires **columnar layout with primitive types**
:::

::::{.callout-tip title="Solution" .fragment}
- **Solution**: split into 3 DataFrames:  
  `patients`, `expositions`, `cancers`
:::

:::
::: {.column width="60%" .fragment}

![](figures/split_df.png)

:::
:::

## Memory Optimization {.smaller}

::: {.callout-important title="Findings" .fragment}
- Most patient features are **invariant** across combinations (*age, BMI, diabetes*…)  
- Sorting the data and downcasting types can significantly reduce memory space.
:::

::: {.callout-note title="Proposal" .fragment}
- Precompute static features. 
- Load data once into memory.
- Save shared data in **Apache Parquet**.
- Minimize queries to the database.  
:::


## Upgrade {.smaller}

::: columns
::: {.column width="35%"}

::: {.callout-tip title="Mechanism"}
0. Precalculate Dataframes
1. Read the Dataframes
2. **CSV** generation with features and the event column
3. **CSV** reading and data preprocessing
4. **COXPH** analysis (using a file as stdout)
5. Read and parse the results
6. Save structured results for later queries
:::

::: {.callout-important title="Improvements"}

- Query-driven -> Reduce time to get data.
- Precalculate shared data -> Avoid repeated queries.
- Use Parquet files -> Efficient storage and fast access.
:::

:::
::: {.column width="65%"}

![](figures/architecture-1.png)

:::
:::


## Code Optimizations^[@baziotisDiasDynamicRewriting2024] {.smaller}

::: columns
::: {.column width="70%"}

#### Non-index-aware

```{.python  code-line-numbers="false"}
cancers_df[cancers_df["loc3"] == "C19"]
```

#### Index-aware

```{.python  code-line-numbers="false"}
cancers_df.loc[(slice(None), "C19"), :]
```

:::
::: {.column width="30%"}

:::{.callout-note title="Results"}
- Non-index-aware: **1.86 ms**
- Index-aware: **247 μs**
:::

:::
:::

####

::: columns
::: {.column width="70%"}

#### Using `isin()`
```{.python  code-line-numbers="false"}
cox_df["has_cancer"] = cox_df.index.isin(with_cancer_df.index)
```

#### Using `loc` with prefill
```{.python  code-line-numbers="false"}
cox_df["has_cancer"] = False
cox_df.loc[with_cancer_df.index, "has_cancer"] = True
```

:::
::: {.column width="30%"}

:::{.callout-note title="Results"}
- Using `isin()`: **3.25 ms**
- Using `loc` with prefill: **464 μs**
:::

:::
:::

::: {.callout-tip title="Summary of Optimizations"}
The total reduction in time is around **52 ms** per combination. For 79,931 combinations, this results in a total time of **~1 hours**.
:::


## Eliminating Communications {.smaller footer=false}

::: columns
::: {.column width="33%"}

::: {.callout-important title="Problem"}
Disk I/O for inter-process communication (IPC) with R is a significant bottleneck.
:::

::: {.callout-tip title="Results"}
We reduce the processing time from **66 seconds to less than 1 second** per combination.

| Function               | Time (ms) |
|------------------------|-----------|
| `get_cox_df`           | 52        |
| `calculate_cox_analysis` | 776       |
| `parse_cox_analysis`   | 22        |
| `save_results`         | 21        |
:::


:::
::: {.column width="67%"}

![](figures/architecture-2.png){fig-align="center"}

:::
:::

## Multithreading {.smaller}

::: {.callout-tip title="Technical Insights" .fragment}

1. Processes outperform threads for CPU-bound tasks -> **Python's Global Interpreter Lock (GIL)** limits threads' performance.
2. Memory usage is higher with processes, which can lead to out-of-memory errors if too many processes are spawned.
3. Threads are more efficient for *I/O-bound tasks*, allowing for **faster startup** and **lower memory** usage.

:::


::: {.callout-important title="Hybrid Strategy" .fragment}
Since threads and processes are not mutually exclusive, we adopted a hybrid approach:

* **Threads**: Efficient for I/O and lightweight parallelism. Used with 2× CPU cores.
* **Processes**: Bypass GIL for CPU-bound tasks. Limited by available RAM.
:::

::: {.callout-note title="Resource Calibration" .fragment}
The hybrid approach allows *fine-tuned* calibration of threads and processes, adapting to the device's CPU and memory capacity. This ensures optimal throughput without exceeding hardware limits.
:::


## Task distribution {.smaller}

::: columns
::: {.column width="70%"}
![](figures/queue.png)

:::
::: {.column width="30%"}

::: {.callout-tip title="Architecture"}
- **Task independence**: Each task is a particular combination of medication and cancer type -> can be processed independently.
- **Task Queue**: Distributes tasks to worker processes (rabbitmq).
- **Worker Processes**: Can be configured to run on different machines, allowing for distributed computing.
- **Task Management**: Each worker fetches tasks from the queue, processes them, and returns results to the main process.
:::

:::
:::

## Deployment {.smaller}

:::: {.callout-tip title="Requirements" .fragment} 
- **Independent combinations** to process.
- **Scalable** and **reproducible** execution. 
:::

. . .

::: {.callout-caution title="Rationale^[@telenykComparisonKubernetesKubernetesCompatible2021]"}

| Feature               | Traditional MPI Cluster               | Kubernetes                          |
|-----------------------|---------------------------------------|-------------------------------------|
| *Resource Allocation* | Static (fixed per job)                |  Dynamic (per-task)               |
| *Scaling*             | Manual intervention required          |   Auto-scaling (HPA + Cluster)     |
| *Fault Tolerance*     | Job fails if worker crashes           |  Self-healing          |

:::


## Scalability {.smaller}


:::{.callout-tip title="Comparative Analysis"}
| Cloud      | Instance type   | Coremark | Workers | vCPUs | Tasks/s | Total time|
|:-----------|:----------------|:---------|:------|:------|:--------|:------------|
| GKE        | e2-highcpu-4    | 51937    | 1     | 4     | 1.0     | 22h 12min   |
|            |                 |          | 2     | 8     | 1.9     | 11h 41min   |
|            |                 |          | 4     | 16    | 3.6     | 06h 10min   |
|            |                 |          | 8     | 32    | 7.0     | 03h 10min   |
|            | c2d-highcpu-4   | 86953    | 4     | 16    | 17.0    | 01h 18min   |
| On-premise | opteron_6247    | 9634     | 1     | 10    | 0.4     | 2d 7h 30min |
|            |                 |          | 2     | 20    | 0.88    | 1d 1h 13min | 
|            |                 |          | 4     | 40    | 2       | 11h 6min    | 
:::

## Conclusions {.smaller}

::: {.callout-tip title="Key Optimizations"}

- **Schema Optimization**  
  Query-driven design and better deserialization.

- **Precomputation & Storage**  
  Eliminated redundant calculations and migrated from CSV to Parquet for columnar efficiency.

- **Compute Efficiency and Communication Overhead**  
  Index-aware queries and optimized pipelines.

- **Parallel Execution**  
  Hybrid threading/multiprocessing to maximize resource utilization.

- **Distributed Scaling**  
  Kubernetes-orchestrated workers with queue-based load balancing.

:::

. . .

::: {.callout-important title="Take Home Messages"}

- **61 Days → ~Hours**  
  Computational throughput improved through systematic optimization.

:::


## References {.smaller footer=false}